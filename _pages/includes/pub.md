
# üìù Publications 
## üéô Speech Synthesis

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2019</div><img src='images/fs.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[FastSpeech: Fast, Robust and Controllable Text to Speech](https://papers.nips.cc/paper/8580-fastspeech-fast-robust-and-controllable-text-to-speech.pdf) \\
**Yi Ren**, Yangjun Ruan, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu

[**Project**](https://speechresearch.github.io/fastspeech/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>

- FastSpeech is the first fully parallel end-to-end speech synthesis model.
- **Academic Impact**: This work is included by many famous speech synthesis open-source projects, such as [ESPNet ![](https://img.shields.io/github/stars/espnet/espnet?style=social)](https://github.com/espnet/espnet). Our work are promoted by more than 20 media and forums, such as [Êú∫Âô®‰πãÂøÉ](https://mp.weixin.qq.com/s/UkFadiUBy-Ymn-zhJ95JcQ)„ÄÅ[InfoQ](https://www.infoq.cn/article/tvy7hnin8bjvlm6g0myu).
- **Industry Impact**: FastSpeech has been deployed in [Microsoft Azure TTS service](https://techcommunity.microsoft.com/t5/azure-ai/neural-text-to-speech-extends-support-to-15-more-languages-with/ba-p/1505911) and supports 49 more languages with state-of-the-art AI quality. It was also shown as a text-to-speech system acceleration example in [NVIDIA GTC2020](https://resources.nvidia.com/events/GTC2020s21420).
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2021</div><img src='images/fs2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[FastSpeech 2: Fast and High-Quality End-to-End Text to Speech](https://arxiv.org/abs/2006.04558) \\
**Yi Ren**, Chenxu Hu, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu

[**Project**](https://speechresearch.github.io/fastspeech2/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:LkGwnXOMwfcC'></span></strong>
  - This work is included by many famous speech synthesis open-source projects, such as [PaddlePaddle/Parakeet ![](https://img.shields.io/github/stars/PaddlePaddle/PaddleSpeech?style=social)](https://github.com/PaddlePaddle/PaddleSpeech), [ESPNet ![](https://img.shields.io/github/stars/espnet/espnet?style=social)](https://github.com/espnet/espnet) and [fairseq ![](https://img.shields.io/github/stars/pytorch/fairseq?style=social)](https://github.com/pytorch/fairseq).
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2024</div><img src='images/mega.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis](https://openreview.net/forum?id=mvMI3N4AvD) \\ 
Ziyue Jiang, Jinglin Liu, **Yi Ren**, et al.

[**Project**](https://boostprompt.github.io/boostprompt/) 
  - This work has been deployed on many TikTok products.
  - Advandced zero-shot voice cloning model.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2022</div><img src='images/diffsinger.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism](https://arxiv.org/abs/2105.02446) \\
Jinglin Liu, Chengxi Li, **Yi Ren**, Feiyang Chen, Zhou Zhao

- Many [video demos](https://www.bilibili.com/video/BV1be411N7JA) created by the [DiffSinger community](https://github.com/openvpi) are released.
- DiffSinger was introduced in [a very popular video](https://www.bilibili.com/video/BV1uM411t7ZJ) (1600k+ views) on Bilibili!

- [**Project**](https://diffsinger.github.io/) \| [![](https://img.shields.io/github/stars/NATSpeech/NATSpeech?style=social&label=DiffSpeech Stars)](https://github.com/NATSpeech/NATSpeech) \| [![](https://img.shields.io/github/stars/MoonInTheRiver/DiffSinger?style=social&label=DiffSinger Stars)](https://github.com/MoonInTheRiver/DiffSinger) \| [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?label=Demo)](https://huggingface.co/spaces/NATSpeech/DiffSpeech)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2021</div><img src='images/portaspeech.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[PortaSpeech: Portable and High-Quality Generative Text-to-Speech](https://arxiv.org/abs/2109.15166) \\
**Yi Ren**, Jinglin Liu, Zhou Zhao

[**Project**](https://portaspeech.github.io/) \| [![](https://img.shields.io/github/stars/NATSpeech/NATSpeech?style=social&label=Code+Stars)](https://github.com/NATSpeech/NATSpeech) \| [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?label=Demo)](https://huggingface.co/spaces/NATSpeech/PortaSpeech)
</div>
</div>

- `AAAI 2024` [Emotion Rendering for Conversational Speech Synthesis with Heterogeneous Graph-Based Context Modeling](https://arxiv.org/abs/2312.11947), Rui Liu, Yifan Hu, **Yi Ren**, et al. [![](https://img.shields.io/github/stars/walker-hyf/ECSS?style=social&label=Code+Stars)](https://github.com/walker-hyf/ECSS)
- ``ICML 2023`` [Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models](https://text-to-audio.github.io/paper.pdf), Rongjie Huang, Jiawei Huang, Dongchao Yang, **Yi Ren**, et al.
- ``ACL 2023`` [CLAPSpeech: Learning Prosody from Text Context with Contrastive Language-Audio Pre-Training](), Zhenhui Ye, Rongjie Huang, **Yi Ren**, et al.



<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2019</div><img src='images/fs.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[FastSpeech: Fast, Robust and Controllable Text to Speech](https://papers.nips.cc/paper/8580-fastspeech-fast-robust-and-controllable-text-to-speech.pdf) \\
**Yi Ren**, Yangjun Ruan, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu

[**Project**](https://speechresearch.github.io/fastspeech/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>

- FastSpeech is the first fully parallel end-to-end speech synthesis model.
- **Academic Impact**: This work is included by many famous speech synthesis open-source projects, such as [ESPNet ![](https://img.shields.io/github/stars/espnet/espnet?style=social)](https://github.com/espnet/espnet). Our work are promoted by more than 20 media and forums, such as [Êú∫Âô®‰πãÂøÉ](https://mp.weixin.qq.com/s/UkFadiUBy-Ymn-zhJ95JcQ)„ÄÅ[InfoQ](https://www.infoq.cn/article/tvy7hnin8bjvlm6g0myu).
- **Industry Impact**: FastSpeech has been deployed in [Microsoft Azure TTS service](https://techcommunity.microsoft.com/t5/azure-ai/neural-text-to-speech-extends-support-to-15-more-languages-with/ba-p/1505911) and supports 49 more languages with state-of-the-art AI quality. It was also shown as a text-to-speech system acceleration example in [NVIDIA GTC2020](https://resources.nvidia.com/events/GTC2020s21420).
</div>
</div> -->


- ``ICMR 2025`` [Edge-Aware Network with Confidence Feature Fusion for Infrared Small Target Detection](https://dl.acm.org/doi/abs/10.1145/3731715.3733318), **Boyuan Li**, Zitong Ren, Xiuhong Li, et al.
- ``ICMR 2025`` [PRNet: Parallel Refinement Network with Selective Feature Enhancement for Infrared Small Target Detection](https://dl.acm.org/doi/abs/10.1145/3731715.3733491), **Boyuan Li**, Xiuhong Li, Kurban Ubul.
- ``ICMR 2025`` [Efficient Camouflaged Object Detection Network Based on Channel Reconstruction and Hybrid Attention](https://dl.acm.org/doi/abs/10.1145/3731715.3733476), Kuan Wang, Xiuhong Li, Songlin Li, Yulong Bai,, **Boyuan Li**, et al. 
<!-- - `ICIC 2025` [TinyDF: Tiny and Effective Model for Deepfake Detection](https://link.springer.com/chapter/10.1007/978-981-96-9958-2_20), Hengyan Guo, Liejun Wang, **Boyuan Li**, et al. -->
- ``ICME 2024`` <span style="color:red">(Oral)</span> [
Adaptive Feature Fusion Network for Infrared Small Target Detection](https://ieeexplore.ieee.org/abstract/document/10687776), **Boyuan Li**, Xiuhong Li, Songlin Li, et al. 
- ``IEEE GRSL 2024`` [Cross-Layer Feature Guided Multiscale Infrared Small Target Detection](https://ieeexplore.ieee.org/document/10415029), **Boyuan Li**, Xiuhong Li, Songlin Li, et al. 
- ``SMC 2024`` <span style="color:red">(Oral)</span> [Mixformer: Feature Mixed Transformer for Rainfall Forecasting](), Yuanyuan Liao, **Boyuan Li<sup>*</sup>** and Xiuhong Li.
- ``MMM 2024`` [Infrared Small Target Detection with Feature Refinement and Context Enhancement](https://link.springer.com/chapter/10.1007/978-981-96-2061-6_10), Xiuhong Li, Xinyue Zhu, **Boyuan Li<sup>*</sup>**, et al.
- ``ICME 2024`` [Lightweight Camouflaged Object Detection Network Based on Feature Complementation and Enhancement](https://ieeexplore.ieee.org/document/10688116), Kangwei Liu, Xiuhong Li, **Boyuan Li**, et al.
- ``ICME 2024`` [Dual Guidance Enhancing Camouflaged Object Detection via Focusing Boundary and Localization Representation](https://ieeexplore.ieee.org/document/10687574), Songlin Li, Xiuhong Li, Zhe Li, Hongbing Ma, Jiabao Sheng, Boyuan Li.
- ``ICIP 2024`` [U-Convnext Network for Infrared Small Target Detection](), Jian Ma, Xiuhong Li, Yuye Zhang, **Boyuan Li**, et al.
- `IJCNN 2024` [AIFENet: Attention-Induced Feature Enhancement Network for Infrared Small Target Detection](https://ieeexplore.ieee.org/document/10650363), Ying Zheng, Xiuhong Li, Yuye Zhang, Kangwei Liu, **Boyuan Li**.
- `IJCNN 2024` [Boundary-Guided Fusion of Multi-Level Features Network for Camouflaged Object Detection](https://ieeexplore.ieee.org/document/10651185), Songlin Li, Zhe Li, **Boyuan Li**, et al.
- `IJCNN 2024` [GPNet: Infrared Small Target Detection via Global Information Enhancement and Position Attention Guidance](https://ieeexplore.ieee.org/document/10649918), Yuye Zhang, Xiuhong Li, Ying Zheng, **Boyuan Li**, et al. 
- `IEEE GRSL 2024` [A Lightweight Two-Level Nested FPN Network for Infrared Small Target Detection](https://ieeexplore.ieee.org/document/10552713), Dangxuan Wu, Xiuhong Li, **Boyuan Li**, et al.
- ``PRCV 2024`` [Camouflaged Object Detection Based on Feature Aggregation and Global Semantic Learning](https://link.springer.com/chapter/10.1007/978-981-97-8858-3_18), Kuan Wang, Xiuhong Li, **Boyuan Li**, et al.
- `PRCV 2023` [Emphasizing Boundary-Positioning and Leveraging Multi-scale Feature Fusion for Camouflaged Object Detection](https://link.springer.com/chapter/10.1007/978-981-99-8555-5_40), Songlin Li, Xiuhong Li, Zhe Li, **Boyuan Li**, et al. 

